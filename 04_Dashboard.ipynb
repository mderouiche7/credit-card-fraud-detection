{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’³ Credit Card Fraud Detection Dashboard\n",
        "\n",
        "ðŸ§ª You can try the app live here:  \n",
        "ðŸ”— [https://mderouiche7-credit-fraud.hf.space](https://mderouiche7-credit-fraud.hf.space)\n",
        "\n",
        "ðŸ“Š Built with Gradio, XGBoost, SHAP.  \n",
        "ðŸ‘¤ Author: [Mohamed Derouiche](https://www.linkedin.com/in/mohamed-derouiche-ba1843294)\n"
      ],
      "metadata": {
        "id": "OYZIyP6lao-t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cnBXk-Et-YVS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lpKA2OByanN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh9vIrLyDCMg",
        "outputId": "1e1ecf58-31b5-4b9f-bbda-0140f74295ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # upload scaler.pkl from your computer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "collapsed": true,
        "id": "1nOVGCrZFuqE",
        "outputId": "933a35d7-b0e7-4de2-cb2d-202179c36835"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8f65049-ba8e-4f70-a346-ce8fcace037a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8f65049-ba8e-4f70-a346-ce8fcace037a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving scaler.pkl to scaler (3).pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'scaler (3).pkl': b'\\x80\\x04\\x95=\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x1bsklearn.preprocessing._data\\x94\\x8c\\x0eStandardScaler\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\twith_mean\\x94\\x88\\x8c\\x08with_std\\x94\\x88\\x8c\\x04copy\\x94\\x88\\x8c\\x11feature_names_in_\\x94\\x8c\\x13joblib.numpy_pickle\\x94\\x8c\\x11NumpyArrayWrapper\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x08subclass\\x94\\x8c\\x05numpy\\x94\\x8c\\x07ndarray\\x94\\x93\\x94\\x8c\\x05shape\\x94K\\x02\\x85\\x94\\x8c\\x05order\\x94\\x8c\\x01C\\x94\\x8c\\x05dtype\\x94h\\x0f\\x8c\\x05dtype\\x94\\x93\\x94\\x8c\\x02O8\\x94\\x89\\x88\\x87\\x94R\\x94(K\\x03\\x8c\\x01|\\x94NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK?t\\x94b\\x8c\\nallow_mmap\\x94\\x89\\x8c\\x1bnumpy_array_alignment_bytes\\x94K\\x10ub\\x80\\x05\\x95\\x9a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x16numpy._core.multiarray\\x94\\x8c\\x0c_reconstruct\\x94\\x93\\x94\\x8c\\x05numpy\\x94\\x8c\\x07ndarray\\x94\\x93\\x94K\\x00\\x85\\x94C\\x01b\\x94\\x87\\x94R\\x94(K\\x01K\\x02\\x85\\x94h\\x03\\x8c\\x05dtype\\x94\\x93\\x94\\x8c\\x02O8\\x94\\x89\\x88\\x87\\x94R\\x94(K\\x03\\x8c\\x01|\\x94NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK?t\\x94b\\x89]\\x94(\\x8c\\x04Time\\x94\\x8c\\x06Amount\\x94et\\x94b.\\x95\\xcb\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x0en_features_in_\\x94K\\x02\\x8c\\x0fn_samples_seen_\\x94\\x8c\\x16numpy._core.multiarray\\x94\\x8c\\x06scalar\\x94\\x93\\x94h\\x18\\x8c\\x02i8\\x94\\x89\\x88\\x87\\x94R\\x94(K\\x03\\x8c\\x01<\\x94NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00t\\x94bC\\x08\\x87X\\x04\\x00\\x00\\x00\\x00\\x00\\x94\\x86\\x94R\\x94\\x8c\\x05mean_\\x94h\\x0b)\\x81\\x94}\\x94(h\\x0eh\\x11h\\x12K\\x02\\x85\\x94h\\x14h\\x15h\\x16h\\x18\\x8c\\x02f8\\x94\\x89\\x88\\x87\\x94R\\x94(K\\x03h(NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00t\\x94bh\\x1e\\x88h\\x1fK\\x10ub\\x0e\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xbf\\xcc\\xd1\\xc0\\xdd%\\xf7@U3l)`\\x16V@\\x95*\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x04var_\\x94h\\x0b)\\x81\\x94}\\x94(h\\x0eh\\x11h\\x12K\\x02\\x85\\x94h\\x14h\\x15h\\x16h3h\\x1e\\x88h\\x1fK\\x10ub\\x0c\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xffG\\xfa\\x03\\xe7J\\xcd\\xe0AG\\xea0.\\xfb\\x8b\\xee@\\x95,\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x06scale_\\x94h\\x0b)\\x81\\x94}\\x94(h\\x0eh\\x11h\\x12K\\x02\\x85\\x94h\\x14h\\x15h\\x16h3h\\x1e\\x88h\\x1fK\\x10ub\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x1bN\\xb3\\x00\\x020\\xe7@\\x99\\xa4vV\\xd4Co@\\x95\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x10_sklearn_version\\x94\\x8c\\x051.6.1\\x94ub.'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploasing model XGBoost best performer and the scaler:\n",
        "model = joblib.load(\"/content/drive/MyDrive/models/xgboost_model.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")"
      ],
      "metadata": {
        "id": "IdLTuBjv_DDq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "# Download dataset from Kaggle\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "# Load the dataset using the full path\n",
        "df = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "# Split train/test (use same random_state as training for consistency)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Now, instead of fitting scaler again, just transform Time and Amount using loaded scaler:\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[['Time', 'Amount']] = scaler.transform(X_test_scaled[['Time', 'Amount']])\n",
        "\n",
        "# Now X_test_scaled is ready for predictions or SHAP analysis"
      ],
      "metadata": {
        "id": "otWeWPguOGYG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load model and scaler (adjust paths)\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Feature names (exclude target)\n",
        "feature_names = [\n",
        "    \"Time\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\",\n",
        "    \"V9\", \"V10\", \"V11\", \"V12\", \"V13\", \"V14\", \"V15\", \"V16\",\n",
        "    \"V17\", \"V18\", \"V19\", \"V20\", \"V21\", \"V22\", \"V23\", \"V24\",\n",
        "    \"V25\", \"V26\", \"V27\", \"V28\", \"Amount\"\n",
        "]\n",
        "\n",
        "# Define UI inputs with sliders with step=0.01 for decimal precision\n",
        "def get_inputs():\n",
        "    return [\n",
        "        gr.Slider(minimum=0, maximum=172792, step=1, value=50000, label=\"Time (seconds)\"),\n",
        "        *[gr.Slider(minimum=-30.0, maximum=30.0, step=0.01, value=0.0, label=feature) for feature in feature_names[1:-1]],\n",
        "        gr.Slider(minimum=0.0, maximum=2500.0, step=0.01, value=50.0, label=\"Amount (Euros)\")\n",
        "    ]\n",
        "\n",
        "# Prediction + SHAP function with input validation (accept dot decimals only)\n",
        "def predict_with_shap(*inputs):\n",
        "    try:\n",
        "        # Convert inputs to float, replace comma with dot if any (reject commas by error)\n",
        "        parsed_inputs = [float(str(x).replace(',', '.')) for x in inputs]\n",
        "        X = np.array(parsed_inputs).reshape(1, -1)\n",
        "\n",
        "        # Extract Time and Amount columns and scale using column names\n",
        "        scaled_df = pd.DataFrame(X[:, [0, -1]], columns=['Time', 'Amount'])\n",
        "        scaled_values = scaler.transform(scaled_df)\n",
        "\n",
        "        # Put scaled values back in X\n",
        "        X[:, 0] = scaled_values[:, 0]  # Scaled Time\n",
        "        X[:, -1] = scaled_values[:, 1]  # Scaled Amount\n",
        "\n",
        "\n",
        "        # Predict fraud probability\n",
        "        pred_prob = model.predict_proba(X)[0][1]\n",
        "\n",
        "        # Compute SHAP values\n",
        "        shap_values = explainer.shap_values(X)\n",
        "\n",
        "       # Plot SHAP bar summary\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        shap.summary_plot(shap_values, X, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"shap_force_plot.png\")\n",
        "        plt.close()\n",
        "\n",
        "        return f\"Fraud Probability: {pred_prob:.4f}\", \"shap_force_plot.png\"\n",
        "\n",
        "    except ValueError:\n",
        "        return \"Error: Please enter decimals using dots (e.g. 6.5), not commas (6,5).\", None\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {str(e)}\", None\n",
        "\n",
        "# Batch prediction for uploaded CSV\n",
        "def batch_predict(file):\n",
        "    try:\n",
        "        if not file.name.endswith(\".csv\"):\n",
        "            return \"Error: Please upload a valid .csv file.\"\n",
        "\n",
        "        df = pd.read_csv(file.name)\n",
        "        X = df[feature_names]\n",
        "\n",
        "        # Scale Time and Amount\n",
        "        X[['Time', 'Amount']] = scaler.transform(X[['Time', 'Amount']])\n",
        "        probs = model.predict_proba(X)[:, 1]\n",
        "        df['Fraud_Probability'] = probs\n",
        "\n",
        "        output_path = f\"batch_predictions_{uuid.uuid4().hex[:6]}.csv\"\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error processing file: {str(e)}\"\n",
        "\n",
        "# Footer and project links\n",
        "\n",
        "description = \"\"\"\n",
        "Provide transaction features to estimate fraud probability using a pre-trained ML model.\n",
        "SHAP explainability will highlight the most influential features.\n",
        "\n",
        "**Input Guide:**\n",
        "- `Time`: Seconds since the dataset's first transaction (range: 0â€“172792)\n",
        "- `Amount`: Transaction amount in Euros (range: 0â€“2500)\n",
        "- `V1â€“V28`: Anonymized PCA components (original features hidden)\n",
        "\n",
        "âš ï¸ Use dot-decimals (e.g., 12.5) â€” do NOT use commas (e.g., 12,5).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Build Gradio app with two tabs (single and batch)\n",
        "single_demo = gr.Interface(\n",
        "    fn=predict_with_shap,\n",
        "    inputs=get_inputs(),\n",
        "    outputs=[\"text\", \"image\"],\n",
        "    title=\"Credit Card Fraud Detection Dashboard\",\n",
        "    description=description,\n",
        "    article=f\"\"\"\n",
        "    <hr>\n",
        "    <p style='text-align:center;'>\n",
        "    <em>Built by Mohamed Derouiche &mdash;\n",
        "    <a href='https://github.com/mderouiche7' target='_blank'>GitHub</a> |\n",
        "    <a href='https://www.linkedin.com/in/mohamed-derouiche-ba1843294' target='_blank'>LinkedIn</a> </em>\n",
        "    </p>\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# Batch prediction interface\n",
        "batch_demo = gr.Interface(\n",
        "    fn=batch_predict,\n",
        "    inputs=gr.File(label=\"Upload CSV with features\"),\n",
        "    outputs=gr.File(label=\"Download Predictions CSV\"),\n",
        "    title=\"Batch Fraud Prediction\"\n",
        ")\n",
        "\n",
        "# Combine into a tabbed interface\n",
        "tabs = gr.TabbedInterface(\n",
        "    interface_list=[single_demo, batch_demo],\n",
        "    tab_names=[\"Single Prediction\", \"Batch Prediction\"]\n",
        ")\n",
        "if __name__ == \"__main__\":\n",
        "    tabs.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "WuTs7F_Y_Hwb",
        "outputId": "fddfcaab-7d73-44c3-ab9f-6c104748717d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://29a413508c9dcc1423.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://29a413508c9dcc1423.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}